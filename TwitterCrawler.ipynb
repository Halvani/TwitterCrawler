{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(username, password, seconds_2_wait = 2):\n",
    "    twitter_login_url = \"https://twitter.com/login\"\n",
    "    driver = webdriver.Chrome(service=Service(path_to_chrome_binary), options=options) \n",
    "    driver.get(twitter_login_url)        \n",
    "    time.sleep(seconds_2_wait)\n",
    "\n",
    "    user = driver.find_element(By.XPATH, \"//input\")\n",
    "    user.send_keys(username)\n",
    "    user.send_keys(Keys.ENTER)        \n",
    "    time.sleep(seconds_2_wait)  \n",
    "    \n",
    "    pw = driver.find_element(By.XPATH, \"//input[@autocomplete='current-password']\")\n",
    "    pw.send_keys(password)\n",
    "    pw.send_keys(Keys.RETURN)    \n",
    "    time.sleep(seconds_2_wait)\n",
    "    \n",
    "    driver.maximize_window()\n",
    "    driver.refresh()\n",
    "    time.sleep(seconds_2_wait)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def perform_query(driver, query):    \n",
    "    search_field = driver.find_element(By.XPATH, \"//input[@enterkeyhint='search']\")\n",
    "    search_field.click()\n",
    "    search_field.send_keys(query)\n",
    "    search_field.send_keys(Keys.RETURN)\n",
    "    \n",
    "    \n",
    "def extract_tweets(driver, verbose=False):    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    articles = soup.find_all(\"article\")\n",
    "    tweets = []\n",
    "    for article in articles:\n",
    "        div = article.find(\"div\", attrs={\"data-testid\":\"tweetText\"})\n",
    "        img = article.find(\"img\", attrs={\"alt\":\"Image\", \"draggable\":\"true\"})\n",
    "        tweet = {\"tweet_text\":div.get_text(), \"image_url\": \"\" if img is None else img[\"src\"]}\n",
    "        tweets.append(json.dumps(tweet))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Tweet text:\\n{tweet['tweet_text']}\")\n",
    "            if img is not None:\n",
    "                print(f\"Image:\\n{tweet['image_url']}\") \n",
    "            print('\\n=============================================================================\\n')\n",
    "    return tweets\n",
    "    \n",
    "    \n",
    "def scroll_down(driver, scroll_threshold=3, sleep_threshold=3, verbose=False): \n",
    "    tweets = []    \n",
    "    for i in tqdm(range(scroll_threshold + 1)):\n",
    "        # Pull tweets..\n",
    "        tweets.extend(extract_tweets(driver, verbose=verbose))\n",
    "        temp = driver.find_element(By.TAG_NAME, \"body\")\n",
    "        temp.send_keys(Keys.END)\n",
    "        time.sleep(sleep_threshold) \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_chrome_binary = PATH_TO_YOUR_CHROMEDRIVER # Download here: https://chromedriver.chromium.org/downloads\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/118.0\"\n",
    "\n",
    "options = webdriver.ChromeOptions() \n",
    "options.add_argument(f\"user-agent=[{user_agent}]\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"detach\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = YOUR_X_USERNAME\n",
    "password = YOUR_X_PASSWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"#Holidays\"\n",
    "scroll_threshold = 3\n",
    "\n",
    "driver = login(username, password)    \n",
    "perform_query(driver, keyword)\n",
    "\n",
    "results = scroll_down(driver, scroll_threshold=scroll_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total crawled tweets: {len(results)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(result)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
